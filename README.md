# AsYouThink

总体规划：

爬虫从网上获取相关的文章数据，之后交给分词系统处理并训练模型，之后使用模型将目标文章的索引信息提出出来，并使用结构化的模式存储到索引数据库中（可能是Mysql，分布式最佳），之后就是正常的JAVAEE项目，获取数据并展示，加上相应的查询。

![image-20221109180537638](./README.assets/image-20221109180537638.png)

定义各部分的任务：

## 1. 前端（Core）

负责数据的展示与相关查询的入口
- 设计Web页面
    - 头一次做，参考其他的网站
    - 搜索主页：发挥创意，简洁设计
    - 统计展示界面，求高级与简洁并存
    
- 定义Json规格
    - 学习axios的使用
    - 简要说明各种需要的Json规格，并给出示例
        - [axios急速上手](https://www.bilibili.com/video/BV1NY411g7cf/?p=15&vd_source=4c4dac1ad6cf7967c0beb4f7457954ce)


## 2. 后端

负责数据的处理

- 搭建后端服务器，用于对数据库进行增删查改

- Hadoop集群的搭建
  - 测试★
- HDFS文件系统搭建
  - 测试★

### 2.1.  爬取

负责爬取数据
- 从网站上爬取文章
    - 说明：首先自行练手，任何网站上均可，爬到一定数量即可
- 将数据存放到HDFS中
- **能否展示当前的爬取结果**

### 2.2. 分词

负责处理文章
- 从数据库中读取文章
- 处理文章得到结果
- 进阶NLP处理

### 2.3. 数据

负责数据的存储研究
- 文章类型数据存储
- 查询数据的存储
- 如何自动更新数据

### 2.4. NLP处理

- ♂

### 2.5. 待办

自定义输入要分析的文章 然后让后台来分析关键词

给出一个大概的后端输出给前端的格式（JSON）